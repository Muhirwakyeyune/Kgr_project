{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport sys\nimport glob\nimport torch\nimport torchvision\n\nimport numpy as np\nimport datetime as dt\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nfrom torch.autograd import Variable\nfrom torch.optim import lr_scheduler\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torchvision import transforms, datasets, models\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\n\n%matplotlib inline\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1.438614,"end_time":"2021-03-29T11:50:48.533762","exception":false,"start_time":"2021-03-29T11:50:47.095148","status":"completed"},"tags":[],"id":"HUl4fAsYltEP","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/ammi-2021-convnets/\"\ntrain_path = join(data_path, \"train/train\")\ntest_path = join(data_path,\"test/test\")\nextraimage_path = join(data_path, \"extraimages/extraimages\")","metadata":{"papermill":{"duration":0.021142,"end_time":"2021-03-29T11:50:48.566314","exception":false,"start_time":"2021-03-29T11:50:48.545172","status":"completed"},"tags":[],"id":"ylUQduBJltEQ","execution":{"iopub.status.busy":"2023-05-19T14:10:50.020451Z","iopub.execute_input":"2023-05-19T14:10:50.020803Z","iopub.status.idle":"2023-05-19T14:10:50.026924Z","shell.execute_reply.started":"2023-05-19T14:10:50.020775Z","shell.execute_reply":"2023-05-19T14:10:50.025896Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['KAGGLE_USERNAME'] = 'muhirwasalomon'\nos.environ['KAGGLE_KEY'] = 'f2e155be15e51da2a38317f327c0669b'\n!kaggle competitions download -c ammi-2023-convnets --force\n!unzip -q ammi-2023-convnets.zip -d ammi-2023-convnets\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM3oUZsIltER","outputId":"ae702af6-633d-45f6-911f-2435a505a099","execution":{"iopub.status.busy":"2023-05-19T14:10:51.214776Z","iopub.execute_input":"2023-05-19T14:10:51.215620Z","iopub.status.idle":"2023-05-19T14:12:24.229341Z","shell.execute_reply.started":"2023-05-19T14:10:51.215588Z","shell.execute_reply":"2023-05-19T14:12:24.227807Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Downloading ammi-2023-convnets.zip to /kaggle/working\n100%|██████████████████████████████████████▉| 2.30G/2.30G [00:13<00:00, 250MB/s]\n100%|███████████████████████████████████████| 2.30G/2.30G [00:14<00:00, 172MB/s]\nreplace ammi-2023-convnets/extraimages/extraimages/extra-image-1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"train_path = 'ammi-2023-convnets/train/train'\ntest_path = 'ammi-2023-convnets/test/test'\n","metadata":{"id":"YmpIE7ARltER","execution":{"iopub.status.busy":"2023-05-19T14:12:28.475568Z","iopub.execute_input":"2023-05-19T14:12:28.476109Z","iopub.status.idle":"2023-05-19T14:12:28.481784Z","shell.execute_reply.started":"2023-05-19T14:12:28.476064Z","shell.execute_reply":"2023-05-19T14:12:28.480621Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom sklearn.utils import class_weight\nfrom collections import Counter\ntorch.random.seed()\n# Define the transformations\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(size=224),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomRotation(degrees=30),\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(255),\n    transforms.RandomResizedCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Compute class weights\ndef compute_class_weights(labels):\n    label_counts = Counter(labels)\n    class_weights = [1.0 / label_counts[label] for label in labels]\n    return torch.tensor(class_weights, dtype=torch.float)\n\nclass CassavaDataset(Dataset):\n    def __init__(self, path, transform=None):\n        self.classes = os.listdir(path)\n        self.path = [f\"{path}/{className}\" for className in self.classes]\n        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n        self.transform = transform\n\n        files = []\n        for i, className in enumerate(self.classes):\n            for fileName in self.file_list[i]:\n                files.append([i, fileName])\n        self.file_list = files\n\n        # Compute class weights\n        labels = [item[0] for item in self.file_list]\n        self.class_weights = compute_class_weights(labels)\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        fileName = self.file_list[idx][1]\n        classCategory = self.file_list[idx][0]\n        im = Image.open(fileName)\n\n        if self.transform:\n            im = self.transform(im)\n\n        return im, classCategory\n","metadata":{"id":"I8cMKd7UMRA5","execution":{"iopub.status.busy":"2023-05-19T15:08:53.110334Z","iopub.execute_input":"2023-05-19T15:08:53.110941Z","iopub.status.idle":"2023-05-19T15:08:53.126195Z","shell.execute_reply.started":"2023-05-19T15:08:53.110909Z","shell.execute_reply":"2023-05-19T15:08:53.125246Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_data = CassavaDataset(train_path, transform=train_transform)\ntest_data = CassavaDataset(test_path, transform=test_transform)","metadata":{"id":"cjyFub42T4eW","execution":{"iopub.status.busy":"2023-05-19T15:08:54.590004Z","iopub.execute_input":"2023-05-19T15:08:54.590365Z","iopub.status.idle":"2023-05-19T15:08:54.636221Z","shell.execute_reply.started":"2023-05-19T15:08:54.590337Z","shell.execute_reply":"2023-05-19T15:08:54.635200Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\nvalidation_split = 0.2\nrandom_seed = 42\nshuffle_dataset = True  # Define shuffle_dataset variable here\n\n# Creating data indices for training and validation splits\ndataset_size = len(train_data)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\n\nif shuffle_dataset:\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n","metadata":{"id":"ZN21b7BbltES","execution":{"iopub.status.busy":"2023-05-19T15:08:55.660343Z","iopub.execute_input":"2023-05-19T15:08:55.660726Z","iopub.status.idle":"2023-05-19T15:08:55.668160Z","shell.execute_reply.started":"2023-05-19T15:08:55.660694Z","shell.execute_reply":"2023-05-19T15:08:55.666929Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"batch_size=8","metadata":{"id":"wRx_UhpGlxq8","execution":{"iopub.status.busy":"2023-05-19T15:08:56.455307Z","iopub.execute_input":"2023-05-19T15:08:56.456172Z","iopub.status.idle":"2023-05-19T15:08:56.460816Z","shell.execute_reply.started":"2023-05-19T15:08:56.456130Z","shell.execute_reply":"2023-05-19T15:08:56.459605Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import SubsetRandomSampler, DataLoader\n\ntrain_sampler = SubsetRandomSampler(train_indices)\nval_sampler = SubsetRandomSampler(val_indices)\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\nval_loader = DataLoader(train_data, batch_size=batch_size, sampler=val_sampler)\ntest_loader = DataLoader(test_data, batch_size=batch_size)\n","metadata":{"id":"DT0LEPV3ltES","execution":{"iopub.status.busy":"2023-05-19T15:08:57.324898Z","iopub.execute_input":"2023-05-19T15:08:57.325907Z","iopub.status.idle":"2023-05-19T15:08:57.333089Z","shell.execute_reply.started":"2023-05-19T15:08:57.325840Z","shell.execute_reply":"2023-05-19T15:08:57.331782Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"\n# Device configuration\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"YHkHGaQ4ltET","execution":{"iopub.status.busy":"2023-05-19T15:08:58.100001Z","iopub.execute_input":"2023-05-19T15:08:58.100385Z","iopub.status.idle":"2023-05-19T15:08:58.106164Z","shell.execute_reply.started":"2023-05-19T15:08:58.100356Z","shell.execute_reply":"2023-05-19T15:08:58.104885Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision.models import resnet50\n\n# Define the ResNet-based model\nclass ResNetClassifier(nn.Module):\n    def __init__(self, num_classes, weight_decay=0.01):\n        super(ResNetClassifier, self).__init__()\n        # Load the pre-trained ResNet50 model\n        self.resnet = resnet50(pretrained=True)\n        \n        # Modify the last fully-connected layer for the desired number of classes\n        num_features = self.resnet.fc.in_features\n        self.resnet.fc = nn.Linear(num_features, num_classes)\n        \n        # Define the weight decay (L2 regularization) for the parameters\n        self.weight_decay = weight_decay\n\n    def forward(self, input):\n        x = self.resnet(input)\n        return x\n\nmodel = ResNetClassifier(num_classes=5)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0002, weight_decay=model.weight_decay)\n","metadata":{"id":"Eo8mfPNCltET","execution":{"iopub.status.busy":"2023-05-19T15:08:58.925112Z","iopub.execute_input":"2023-05-19T15:08:58.925473Z","iopub.status.idle":"2023-05-19T15:08:59.420069Z","shell.execute_reply.started":"2023-05-19T15:08:58.925444Z","shell.execute_reply":"2023-05-19T15:08:59.419079Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Ake3uiLHlMO8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #weights initialization\n# def initalize_weights(m):\n#     classname = m.__class__.__name__\n#     if classname.find('Conv') != -1:\n#         nn.init.normal_(m.weight.data, 0.0, 0.02) #Initialize the weights to mean=0, sd=0.02\n#     elif classname.find('BatchNorm') != -1:\n#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n#         nn.init.constant_(m.bias.data, 0)","metadata":{"id":"itc4nwY3ojxu","execution":{"iopub.status.busy":"2023-05-19T15:09:00.485559Z","iopub.execute_input":"2023-05-19T15:09:00.485957Z","iopub.status.idle":"2023-05-19T15:09:00.490689Z","shell.execute_reply.started":"2023-05-19T15:09:00.485924Z","shell.execute_reply":"2023-05-19T15:09:00.489727Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"\n\n# import numpy as np\n# from sklearn.model_selection import KFold\n\n# def train(model, criterion, train_data, optimizer, num_epochs, num_folds):\n#     \"\"\"Train a model using cross-validation.\"\"\"\n#     kf = KFold(n_splits=num_folds, shuffle=True)\n\n#     print('----- Cross-validation Loop -----')\n#     # Loop over folds.\n#     for fold, (train_indices, val_indices) in enumerate(kf.split(train_data)):\n#         print(f'Fold: {fold + 1}')\n\n#         # Reset model parameters for each fold.\n        \n\n#         # Exponential moving average of the loss.\n#         ema_loss = None\n\n#         print('----- Training Loop -----')\n\n#         # Loop over epochs.\n#         for epoch in range(num_epochs):\n#             # Training phase\n#             model.train()\n\n#             # Loop over training data.\n#             for batch_idx, (features, target) in enumerate(train_loader):\n#                 # Move data to the device.\n#                 features = features.to(device)\n#                 target = target.to(device)\n\n#                 # Forward pass.\n#                 output = model(features)\n#                 loss = criterion(output, target)\n\n#                 # Backward pass.\n#                 optimizer.zero_grad()\n#                 loss.backward()\n#                 optimizer.step()\n\n#                 # Update exponential moving average of the loss.\n#                 if ema_loss is None:\n#                     ema_loss = loss.item()\n#                 else:\n#                     ema_loss += (loss.item() - ema_loss) * 0.01\n\n#             # Print training progress at the end of the epoch.\n#             print('Fold: {} \\tEpoch: {} \\tTraining Loss: {:.3f}'.format(fold + 1, epoch, ema_loss))\n","metadata":{"papermill":{"duration":0.024895,"end_time":"2021-03-29T11:50:49.499328","exception":false,"start_time":"2021-03-29T11:50:49.474433","status":"completed"},"tags":[],"id":"STGB7v9RltET","execution":{"iopub.status.busy":"2023-05-19T15:09:01.185601Z","iopub.execute_input":"2023-05-19T15:09:01.186575Z","iopub.status.idle":"2023-05-19T15:09:01.193300Z","shell.execute_reply.started":"2023-05-19T15:09:01.186541Z","shell.execute_reply":"2023-05-19T15:09:01.192153Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef train(model, criterion, train_loader, val_loader, optimizer, num_epochs, patience):\n    \"\"\"Train a model with early stopping.\"\"\"\n   \n\n    # Exponential moving average of the loss.\n    ema_loss = None\n\n    # Variables for early stopping\n    best_loss = np.inf\n    epochs_without_improvement = 0\n\n    print('----- Training Loop -----')\n\n    # Loop over epochs.\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n\n        # Loop over training data.\n        for batch_idx, (features, target) in enumerate(train_loader):\n            # Move data to the device.\n            features = features.to(device)\n            target = target.to(device)\n\n            # Forward pass.\n            output = model(features)\n            loss = criterion(output, target)\n\n            # Backward pass.\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # Update exponential moving average of the loss.\n            if ema_loss is None:\n                ema_loss = loss.item()\n            else:\n                ema_loss += (loss.item() - ema_loss) * 0.01\n\n        # Print training progress at the end of the epoch.\n        print('Epoch: {} \\tTraining Loss: {:.3f}'.format(epoch, ema_loss))\n\n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n\n        with torch.no_grad():\n            for val_data in val_loader:\n                val_inputs, val_labels = val_data\n                val_inputs = val_inputs.to(device)\n                val_labels = val_labels.to(device)\n\n                val_outputs = model(val_inputs)\n                loss = criterion(val_outputs, val_labels)\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        # Check if validation loss has improved\n        if val_loss < best_loss:\n            best_loss = val_loss\n            epochs_without_improvement = 0\n        else:\n            epochs_without_improvement += 1\n\n        ","metadata":{"execution":{"iopub.status.busy":"2023-05-19T15:09:01.965621Z","iopub.execute_input":"2023-05-19T15:09:01.966379Z","iopub.status.idle":"2023-05-19T15:09:01.978520Z","shell.execute_reply.started":"2023-05-19T15:09:01.966333Z","shell.execute_reply":"2023-05-19T15:09:01.977150Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# def test(model, data_loader):\n#     \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n#     # Make sure the model is in evaluation mode.\n#     model.eval()\n#     correct = 0\n#     print('----- Model Evaluation -----')\n#     # We do not need to maintain intermediate activations while testing.\n#     with torch.no_grad():\n\n#         # Loop over test data.\n#         for features, target in data_loader:\n\n#             # Move data to the device.\n#             features = features.to(device)\n#             target = target.to(device)\n\n#             # Forward pass.\n#             output = model(features)\n\n#             # Get the label corresponding to the highest predicted probability.\n#             pred = output.argmax(dim=1, keepdim=True)\n\n#             # Move tensors to the same device as the model.\n#             pred = pred.to(device)\n#             target = target.to(device)\n\n#             # Count number of correct predictions.\n#             correct += pred.eq(target.view_as(pred)).sum().item()\n\n#     # Print test accuracy.\n#     percent = 100. * correct / len(val_sampler)\n#     print(f'Test accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n#     torch.save(model.state_dict(), 'model.ckpt')\n#     return percent\n","metadata":{"papermill":{"duration":0.024848,"end_time":"2021-03-29T11:50:49.536153","exception":false,"start_time":"2021-03-29T11:50:49.511305","status":"completed"},"tags":[],"id":"YF4yBlZgltEU","execution":{"iopub.status.busy":"2023-05-19T15:09:02.944995Z","iopub.execute_input":"2023-05-19T15:09:02.945358Z","iopub.status.idle":"2023-05-19T15:09:02.951897Z","shell.execute_reply.started":"2023-05-19T15:09:02.945330Z","shell.execute_reply":"2023-05-19T15:09:02.950927Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"def test(model, data_loader):\n    \"\"\"Measures the accuracy of a model on a data set.\"\"\"\n    # Make sure the model is in evaluation mode.\n    model.eval()\n    correct = 0\n    total = 0\n\n    print('----- Model Evaluation -----')\n    # We do not need to maintain intermediate activations while testing.\n    with torch.no_grad():\n        # Loop over test data.\n        for features, target in data_loader:\n            # Move data to the device.\n            features = features.to(device)\n            target = target.to(device)\n\n            # Forward pass.\n            output = model(features)\n\n            # Get the label corresponding to the highest predicted probability.\n            _, predicted = torch.max(output.data, 1)\n\n            # Count number of correct predictions.\n            total += target.size(0)\n            correct += (predicted == target).sum().item()\n\n    # Calculate test accuracy.\n    accuracy = 100 * correct / total\n    print(f'Test accuracy: {correct} / {total} ({accuracy:.2f}%)')\n\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T15:09:03.785159Z","iopub.execute_input":"2023-05-19T15:09:03.785894Z","iopub.status.idle":"2023-05-19T15:09:03.794671Z","shell.execute_reply.started":"2023-05-19T15:09:03.785832Z","shell.execute_reply":"2023-05-19T15:09:03.793720Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"num_epochs = 15\npatience = 3\ntrain(model, criterion, train_loader, val_loader, optimizer, num_epochs, patience)\ntest(model, val_loader)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXoZGg2opKdw","outputId":"ac2e8aa9-2cea-4441-e9ad-2906a67811ce","execution":{"iopub.status.busy":"2023-05-19T15:09:05.700070Z","iopub.execute_input":"2023-05-19T15:09:05.700747Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"----- Training Loop -----\nEpoch: 0 \tTraining Loss: 0.998\nEpoch: 1 \tTraining Loss: 0.960\nEpoch: 2 \tTraining Loss: 1.041\n","output_type":"stream"}]},{"cell_type":"code","source":"test(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T10:41:28.677433Z","iopub.status.idle":"2023-05-19T10:41:28.678147Z","shell.execute_reply.started":"2023-05-19T10:41:28.677867Z","shell.execute_reply":"2023-05-19T10:41:28.677891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# test(model, test_loader)","metadata":{"papermill":{"duration":0.024454,"end_time":"2021-03-29T12:00:25.51629","exception":false,"start_time":"2021-03-29T12:00:25.491836","status":"completed"},"tags":[],"id":"N2M4fnG9ltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.679381Z","iopub.status.idle":"2023-05-19T10:41:28.680071Z","shell.execute_reply.started":"2023-05-19T10:41:28.679814Z","shell.execute_reply":"2023-05-19T10:41:28.679837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir\nfrom PIL import Image\nimport torch\nimport torch.nn.functional as F\nfrom torchvision import transforms\n\n# Step 1\ntest_directory = \"ammi-2023-convnets/test/test/0\"\npredictions, test_image_fileName = [], []\n\n# Step 2\n# Process image\ndef preprocess_image(image):\n    image = image.resize((224, 224))\n    image = transforms.ToTensor()(image)\n    image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n    return image\n\n# Step 3\ndef predict(image, model):\n    # Pass the image through the model\n    output = model(image.to(device))\n    # Reverse the log function of the output\n    output = torch.exp(output)\n    # Get the predicted class\n    _, predicted_class = output.max(1)\n    return predicted_class.item()\n\n# Step 4\n# Get the list of class names\nclass_names = train_loader.dataset.classes\n\n# Step 5\ntry:\n    # Iterate over the test images\n    test_images = listdir(test_directory)\n    for image_name in test_images:\n        # Check if the item is not a directory\n        if not os.path.isdir(os.path.join(test_directory, image_name)):\n            # Get the image path\n            image_path = os.path.join(test_directory, image_name)\n            print(f\"Preprocess image: {image_path}\")\n            \n            # Open and preprocess the image\n            image = Image.open(image_path)\n            image = preprocess_image(image)\n            image = image.unsqueeze(0).to(device)\n            \n            # Perform the prediction on the image\n            with torch.no_grad():\n                top_class = predict(image, model)\n                # Add the predicted class and image name to the list\n                predictions.append(class_names[top_class])\n                test_image_fileName.append(image_name)\n                # Print the prediction result for the image\n                print(f\"Prediction for image {image_path}: {class_names[top_class]}\")\n\n    # Sort predictions and image filenames based on predictions\n    sorted_predictions, sorted_filenames = zip(*sorted(zip(predictions, test_image_fileName)))\n    predictions = list(sorted_predictions)\n    test_image_fileName = list(sorted_filenames)\n\nexcept Exception as e:\n    # Handle any exceptions that occur during the process\n    print(e)\n","metadata":{"papermill":{"duration":0.024454,"end_time":"2021-03-29T12:00:25.51629","exception":false,"start_time":"2021-03-29T12:00:25.491836","status":"completed"},"tags":[],"id":"uK8iNi3IltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.681340Z","iopub.status.idle":"2023-05-19T10:41:28.682010Z","shell.execute_reply.started":"2023-05-19T10:41:28.681767Z","shell.execute_reply":"2023-05-19T10:41:28.681790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make submission here","metadata":{"papermill":{"duration":0.023453,"end_time":"2021-03-29T12:00:25.554652","exception":false,"start_time":"2021-03-29T12:00:25.531199","status":"completed"},"tags":[],"id":"AGt1k3DtltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.683252Z","iopub.status.idle":"2023-05-19T10:41:28.683934Z","shell.execute_reply.started":"2023-05-19T10:41:28.683689Z","shell.execute_reply":"2023-05-19T10:41:28.683713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_data = {\"Category\": predictions, \"Id\": test_image_fileName}\nsubmission_data_frame = pd.DataFrame(submission_data)\n\n# Save the DataFrame to CSV\nsubmission_data_frame.to_csv('/kaggle/working/submission_file5.csv', index=False)\n","metadata":{"papermill":{"duration":0.01493,"end_time":"2021-03-29T12:00:25.584744","exception":false,"start_time":"2021-03-29T12:00:25.569814","status":"completed"},"tags":[],"id":"S0hXfromltEU","execution":{"iopub.status.busy":"2023-05-19T10:41:28.685183Z","iopub.status.idle":"2023-05-19T10:41:28.685866Z","shell.execute_reply.started":"2023-05-19T10:41:28.685622Z","shell.execute_reply":"2023-05-19T10:41:28.685645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nsubmission_data = {\"Category\": predictions, \"Id\": test_image_fileName}\nsubmission_data_frame = pd.DataFrame(submission_data)\n\n# Save the DataFrame to CSV\nsubmission_data_frame.to_csv('/kaggle/working/submission_file4.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T10:41:28.687080Z","iopub.status.idle":"2023-05-19T10:41:28.687775Z","shell.execute_reply.started":"2023-05-19T10:41:28.687529Z","shell.execute_reply":"2023-05-19T10:41:28.687552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}